{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajlewis02/MLGroupProject/blob/fashion_mnist/mpgeary_MLFinalProj_FMNIST_NovelPrunedModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "**Fashion MNIST Convolutional Neural Network - Novel Prune**\n",
        "1. Define Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EtMdoFdMS8G"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.prune as prune\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "class FashionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FmJS-FDPgey"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils import prune\n",
        "\n",
        "def train(model, device, train_loader, optimizer):\n",
        "\n",
        "    for batch_index, (inputs, labels) in enumerate(train_loader):\n",
        "      model.train()\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      output = model(inputs)\n",
        "      loss = F.nll_loss(output, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch_index in (333, 666):\n",
        "        print('pruning!')\n",
        "        to_prune = ((model.conv1, \"weight\"), (model.conv2, \"weight\"), (model.fc1, \"weight\"), (model.fc2, \"weight\"))\n",
        "        prune.global_unstructured(to_prune, pruning_method=prune.L1Unstructured, amount=0.17)\n",
        "\n",
        "      if batch_index % 100 == 0:\n",
        "        print('Training Progress: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            batch_index * len(inputs), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Build Confusion Matrix/ Collect Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgTrvN0SPilP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "def buildConfusionMatrix(model, testloader, device):\n",
        "  # iterate over test data\n",
        "  for inputs, labels in testloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          output = model(inputs) # Feed into Network\n",
        "\n",
        "          output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "          y_pred.extend(output) # Save Prediction\n",
        "          \n",
        "          labels = labels.data.cpu().numpy()\n",
        "          y_true.extend(labels) # Save Truth\n",
        "\n",
        "  # constant for classes\n",
        "  classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "          'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "  # Build confusion matrix\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, \n",
        "                       index = [i for i in classes],\n",
        "                       columns = [i for i in classes])\n",
        "  plt.figure(figsize = (12,7))\n",
        "  sn.heatmap(df_cm, annot=True)\n",
        "  plt.title(\"Confusion Matrix - Custom Pruned Model\")\n",
        "  plt.show()\n",
        "\n",
        "  print(classification_report(y_true, y_pred, target_names=list(classes)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Main function compiling previous steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e5SCXGnPrWP"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "\n",
        "    torch.manual_seed(1)\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    train_kwargs = {'batch_size': 64}\n",
        "    test_kwargs = {'batch_size': 1000}\n",
        "    if use_cuda:\n",
        "        cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n",
        "        train_kwargs.update(cuda_kwargs)\n",
        "        test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "\n",
        "    dataset1 = datasets.FashionMNIST('../data', train=True, download=True,\n",
        "                       transform=transform)\n",
        "    dataset2 = datasets.FashionMNIST('../data', train=False,\n",
        "                       transform=transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "    model = FashionModel().to(device)\n",
        "    optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
        "\n",
        "    if use_cuda:\n",
        "      start = torch.cuda.Event(enable_timing=True)\n",
        "      end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "      start.record()\n",
        "      train(model, device, train_loader, optimizer)\n",
        "      end.record()\n",
        "      torch.cuda.synchronize()\n",
        "      print(\"\\nTotal training time (1 epoch): \" \n",
        "            + str(start.elapsed_time(end)/1000) + \" seconds\")\n",
        "\n",
        "    else:\n",
        "      train(model, device, train_loader, optimizer)\n",
        "    \n",
        "    buildConfusionMatrix(model, val_loader, device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMYW5XjZNVevklKfa+0c7Hv",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "mpgeary-MLFinalProj-FMNIST-NovelPrunedModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
